# basic

## 大纲
- 时间复杂度分析
- 数组
- 查找问题
- 链表
- 栈、队列、优先队列
- 二叉树、递归
- 回溯
- 动态规划
- 贪心算法

## 2.时间复杂度分析

### 2-1 什么是大O
> n表示数据规模，O(f(n))表示运行算法所需要执行的指令数，和f(n)成正比

1. 二分查找法O(logn),所需指令数:`a*logn`;
寻找数组中的最大/最小值O(n),所需指令数:`b*n`;
归并排序所需指令数：`c*nlogn`;
选择排序所需指令数：`dn^2`;

因为算法讨论的都是超大数据量下的问题，时间复杂度大O讨论的是一个量级的问题，当n突破某个点的时候「时间复杂度低的算法」需要的时间一定比「时间复杂度高」的算法少。

但是同理如果数据量小的情况下，复杂度高的算法在前面的常数级参数里可能会有小的优势。例如在进行归并排序与快排时，数据量很小时可以考虑用插入排序来进行优化。

2. 在学术界，严格地将，O(f(n))表示算法执行的上界；

归并排序算法的时间复杂度是O(nlogn)的，同时也是O(n^2)

在业界，我们使用O来表示算法执行的最低上界

我们一般不会说归并排序是O(n^2)，而是O(nlogn)

3. 如果设计了一个算法有两个部分，那么整个算法应该以量级高的算法作为主导。如某个算法时间复杂度是`O(nlogn + n)`的，那么这个算法的时间复杂度应该是`O(nlogn)`。

但是如果`O(AlogA + B)`,两部分的维度并不是相同的n，那么就不能省略掉B部分

例如对邻接表实现图的遍历，时间复杂度是O(V + E)

```
// 问题：有一个字符串数组，将数组中的每一个字符串按照字母序排序；之后再将整个字符串数组按照字典序排序。整个操作的时间复杂度是多少？


// 解：1.假设最长字符串的长度为s；数组中有n个字符串
对每个字符串排序O(slogs)
2. 将数组中每个字符串按照字母序排序O(n*slog(s))
3. 将整个字符串数组按照字典序排序O(s*nlog(n))，原因：对于计算机来说，「整数的比较」时间复杂度是O(1)级别的，所以整数排序是O(nlogn)级别的；但是「字符串的比较」时间复杂度是O(s)级别的，所以字符串排序的时间复杂度是O(s*nlog(n))级别的。
4. 所以该题解是O(n*slog(s))+O(s*nlog(n))=O(n*s*logs+s*n*logn)=O(n*s*(logn+logs))
```

4. 算法复杂度在有些情况是用例相关的：

比如插入排序算法O(n^2)，最差情况O(n^2)，最好情况是O(n)，即是在原数组本身有序的情况下。但是这个算法的平均情况是O(n^2)的。

比如快速排序算法O(nlogn)，最差情况O(n^2)，即每次partition选取的值刚好是这个区间的最值;最好情况是O(nlogn)。但是这个算法的平均情况是O(nlogn)的。


### 2-2 对数据规模有个概念
如果想要在1s之内解决问题：
1. O(n^2)的算法可以处理大约10^4级别的数据: 10000
2. O(n)的算法可以处理大约10^8级别的数据: 1000万
3. O(nlogn)的算法可以处理大约10^7级别的数据: 100万

不同的计算机速度也不同，而且不同算法单次实际运行的时间也不同。通常建议将数据级别再除以10。


#### 空间复杂度
1. 多开一个辅助数组O(n)
2. 多开一个辅助的二维数组O(n^2)
3. 多开常数空间O(1)

ps. 递归调用是有空间代价的，因为语言通常需要将前一级函数的状态压入栈中。

例如正常计算空间复杂度为O(1)，那么递归调用空间复杂度是O(n)


### 2-3 常见的复杂度分析
1. 顺序执行，没有循环的操作，复杂度为O(1)
2. 存在一个for循环，通常复杂度为O(n)。值得注意的是，这个n前面通常带一个常数a，这个a可能大于1也有可能小于1。如下
```go
for i:= 0; i < n/2; i++ {
    // 
}
```
这个算法的复杂度是O(1/2*n)，仍然是O(n)级别的复杂度。
  
3. 存在一个嵌套的for循环,并且两次循环的次数都与n有关系，通常复杂度为O(n^2)。
```go
// O(n^2)的数学推导
for i:=0;i<n;i++ {
    minIndex := i
    for j:=i+1;j<n;j++ {
        // todo
    }
}
// 对于上面这段代码，执行todo操作次数为:
// (n-1) + (n-2) + (n-3) + ...+ 0
// = (0+n-1)*n/2    等差数列求和
// = (1/2)n*(n-1)
// = 1/2*n^2 - 1/2*n
// = O(n^2)
```

4. 复杂度O(logn)
例1:二分查找法的复杂度是O(logn)的，因为它的流程是：
    1. 在n个元素中查找；
    2. 在n/2个元素中查找；
    3. 在n/4个元素中查找；
    4. ... 直到在1个元素中查找。

    n经过以2为底logn次「除以2」操作后等于1,即log2(n) = O(logn)  // 这里log2(n)表示为log2为底的n
    
例2:
```php
while(num) {
    //  todo
    num/=10
}
```
n经过几次「除以10」操作后等于0？即log10(n) = O(logn)
而loga(n) 与logb(n)之间的关系是: loga(n) = loga(b) * logb(n), 即loga(n)与logb(n)之前的关系是loga(b)级的，是常数级的关系，是相对可以忽略不计的。


5. 复杂度O(nlogn)
```go
for sz := 1; sz < n; sz +=sz {
    for i := 1; i  < n; i++  {
        fmt.Println("hello")
    }
}
```
对于上面这段代码，里面的循环走了n次，而外面的循环每次都是sz*2直到大于等于n，即n/2与sz的关系，是logn级别的。所以整个代码复杂度为O(nlogn)


6. 了解：复杂度O(sqrt(n)) 根号n级别的算法
```go
for i := 2 ; i*i <= n; i++ {

}
```

### 2-4 复杂度检查
自以为写了O(nlogn)算法，实际是O(n^2)的算法。如何检测。

方法：每次将数据规模提高两倍，看时间的变化。

### 2-5 递归算法的复杂度分析
**不是有递归的函数就一定是O(nlogn)!**

1. 递归中只进行一次递归调用，只要计算出递归调用的深度。
> 如果在递归调用中，只进行一次递归调用，递归深度为depth，在每个递归函数中，时间复杂度为T；则总体的时间复杂度为O(T*depth)

例如二分查找法的递归写法，递归调用的深度每次是n/2级别的，所以其时间复杂度是O(logn)级别的。
```go
func binarySearch(arr []int, l int, r int, target int) int {
    if l > r {
        return -1
    }

    mid := (r - l) / 2  + l
    if arr[mid] == target {
        return mid
    } else if arr[mid] > target {
        return binarySearch(arr, l, mid - 1, target)
    } else {
        return binarySearch(arr, mid + 1, r, target)
    }
}
```

例2:计算x的n次方：x^n = x^(n/2) * x^(n/2)
```go
func pow(x float64, n int) (float64, error) {
    if n < 0 {
        return 0, error.New("非法")
    }
    if n  == 0 {
        return 1.0
    }

    t := pow(x, n/2)

    if n%2 {
        return x*t*t
    }
    return t*t
}
```
注意一般求x^n，通常是连续n个x相乘，即复杂度为O(n)。这个算法的递归深度是logn，时间复杂度是O(logn)，要比传统的n个x相乘性能要好很多。


2. 递归中进行多次的递归调用，重点在计算调用的次数。可以将整个递归过程画成一棵树，则问题变化成求这棵树的节点次数。

如一棵二叉树：2^0+2^1+2^2+2^3+...+2^n = 2^(n+1)-1 = O(2^n)。这是一个指数级算法，性能是极其慢的。

但是在如归并排序的多次递归写法中：整棵树的深度是logn，并且每个节点的数据处理规模都是逐渐缩小的。所以复杂度是O(nlogn)级别的。
```go
func mergeSort(arr []int, l int, r int) {
    if l >= r {
        return
    }
    mid := (r - l) / 2 + l
    mergeSort(arr, l, mid)
    mergeSort(arr, mid+1,r)
    merge(arr, l, mid,  r)
}
```

3. 课外扩展 **主定理**：递归函数的时间复杂度的所有情况。


### 2-6 均摊时间复杂度分析
例：动态数组Vector添加元素的时间复杂度分析：在添加元素时如果数组长度已经等于容量capacity了，则执行resize操作，将数组容量翻倍。这个数组容量翻倍操作需要遍历整个数组，将其移动到新开辟的容量翻倍的数组中，这个复杂度为O(n)。而如果正常添加元素的操作，因为是直接添加到数组尾部，故复杂度为O(1)。

所以计算均摊复杂度时，添加n个元素时间复杂度为O(n)，resize操作为O(n)，则整体复杂度为O(2n)，故添加单个元素的复杂度为O(2)，就是O(1)。

> ps 关于动态数组的resize操作为什么数组大小n每次都要翻倍的原因：因为如果每次容量增加一个常数，假如这个常数是10000，那么在数据量在千万级别的时候这10000个新空间太小了，会导致过多的resize操作。而如果数据量在10级别的时候，这个新空间又太大了，极大浪费了空间。所以这个新空间大小最好是与数组大小n有关，所以一般选择与数组大小有关的最小的值，即2n。

### 2-7 避免复杂度的震荡
同样是动态数组vector，如果在弹出元素时，当前元素个数是容量的二分之一，那么进行resize操作，删除掉空的一半空间。这里就会出现复杂度震荡的问题。

如果数组容量在n，数组元素个数也在n，此时添加元素加resize的复杂度为O(n)；然后又删除一个元素，此时删除元素加resize的复杂度为O(n)；我们在这个临界点反复横跳，就会导致整体的添加元素与删除元素的复杂度由O(1)变成O(n)。这就是复杂度震荡的问题。

最好的解决思路是，在当前元素个数是容量的四分之一的时候再进行resize减少一半空间，这样保证了再添加操作时仍然有元素个数两倍的空间。


## 3. 最常见的问题：数组

### 3-1 3-2 写出正确的程序
根据二分查找法来进行分析：
1. **严格限定变量的实际意义**。如定义数组边界的两个变量l与r，如果设定为l=0,r=n-1，则查找区间是`[l...r]`这个闭区间内。如果l=-1，r=n，则查找区间就变成了`(l...r)`这个开区间内。

2. 注意边界问题。
3. 注意题目中会不会有溢出的问题。
4. 小数据量调试：单元测试
5. 大数据量测试：性能测试

### 3-3 3-4 3-5 3-6 开始解决算法问题：数组
**面对问题不要想当然**
注意如果题干没有提及，那么可以询问面试官题目的具体要求，例如一道题目要求在数组中删除特定的元素，问题一般有：
- 如何定义删除？从数组中去除？还是放在数组的末尾？
- 剩余元素的排列是否要保证原有的相对顺序？
- 是否有空间复杂度的要求？O(1)

如果是查找题，则问题一般有：
- 如果没有解？ （通常会保证有解，或者返回0）
- 如果有多个解？ （返回任意解，或者返回最大/小解，返回所有解，那所有解的顺序是怎么样的？）

如果是字符串的问题，一般有：
- 空字符串如何看?例如回文题，空字符串是否被看为回文
- 字符的定义? 只有数字+字母，还是所有ascii码都取
- 大小写的问题?
- 子串的定义？例如"pwwkew"，"wke"是一个子串，那"pwke"是不是子串？（这个通常称为子序列）

如果是数组问题：
- 什么是子数组？有的题目会要求子数组是连续的

**在实现完代码后，一定要想，我能不能做的更好？**

**但是注意,通常算法是无法兼顾时间复杂度与空间复杂度的**

#### 单元测试的写法(自己逐步归纳)
##### 测试用例
1. 非法数据
2. 边际数据
3. 完全不符合条件的数据
4. 空数据
5. 负数/小数
6. 长度很大的数据；


## 4. 查找问题
### 4-1 4-2 4-3 4-4 4-5 4-6 实战
一般有两类查找问题：
1. 查找有无，元素a是否存在？一般用set集合；
2. 查找对应关系（键值对应）某个元素a出现了几次？一般用map字典

对于查找问题，可以通过辅助的数据结构来进行解答。除了上面的set与map两种结构，还可以实现一些更加底层的结构，下面做一下几个结构的时间复杂度比较
1. 普通数组：插入O(1),查找O(n),删除O(n)
2. 顺序数组：插入O(n),查找O(logn)(二分搜索),删除O(n)
3. 二分搜索树（平衡）：插入O(logn),查找O(logn),删除O(logn)
4. 哈希表：插入O(1),查找O(1),删除O(1)。但是哈希表失去了数据的顺序性（unordered）。

通常问题使用哈希表就可以解决了，如果对顺序有要求的可以考虑使用平衡二叉树

#### 时间复杂度的问题 
我们在解答问题时会经常使用辅助的数据结构。所以如果计算时间复杂度，还要看这些结构操作的时间复杂度。例如一次循环，每次循环往二分搜索树中查找数据，那么时间复杂度应该是循环的时间复杂度O(n)加上二分搜索树查找数据的时间复杂度O(logn),也就是O(nlogn)

#### 数据规模
1. 题目中有时直接给了数据规模的取值范围,例如454题,直接说了数组的元素个数在`[0...500]`这个区间内;根据这个数据规模的取值范围,就能推测出大概需要一个什么时间复杂度的算法.

    例如454需要在四个数组中做查找,暴力解法的时间复杂度为O(n^4),即500^4;即使将最后一个数组放入查找表,也需要500^3次循环.所以这里应该是设计一个至少是n^2级别的算法.即需要将两个数组的元素放入查找表.

2. 如果题目中出现了除法、开根号等操作,需要考虑到计算结果的数据类型从int转变为float; 同理如果出现乘法,也要考虑到int转变成int64的可能.


## 5. 链表问题
### 5-1 5-2 5-3 实战注意问题
1. 通常链表题目是不能改变链表节点的值的,而是对节点的next/pre进行操作;

2. 一定要判断当前链表是否等于nil,尤其存在删除操作时.另外go语言里定义了链表结构,delete操作是不能写成链表结构的地址类型的成员方法的`func (l *ListNode) delete(val int) bool`,因为这里的头节点`l`不是一个变量,如果有删除头节点的操作,但是`l`是不能修改的,这里不会出现报错,而是会导致头节点的重新赋值操作失败!

## 6. 栈、队列、优先队列
### 栈与递归的关系
函数递归是通过栈来实现的

### 队列
队列经常用于广度优先遍历,如:树的层次遍历;无权图的最短路径

### 优先队列
优先队列的底层实现是堆,出队的是权值最高的数据.

## 7. 二叉树与递归
### 递归
递归算法的内容有 : 1. 递归终止条件;2. 递归调用逻辑; 

> 二分搜索树：若左子树不为空，左子树上所有节点都比根节点小；若右子树不为空，右子树上所有节点都比根节点大。
可以知道二叉树的定义天然递归: 1. 递归终止条件: "若左子树/右子树不为空"; 2. 递归调用逻辑: 左子树/右子树所有节点都比根节点小/大


## 8. 回溯
> 递归调用的一个重要特征: 需要返回; 这个流程就是回溯.

1. 回溯法的时间复杂度一般都比较高,回溯法是暴力解法的主要实现手段.
2. 回溯法的流程通常是固定的(见leetcode解题,用回溯法的答案总体框架都是固定的)

回溯法解决:
1. 排列问题
2. 组合问题

回溯法的剪枝:

### 8-7 floodfill算法
在某个初始点开始,进行深度优先遍历

> 回溯法是经典人工智能的基础;


## 9. 动态规划
什么是动态规划?
对于斐波那契数列,有如下实现方式
```go
func fib(n int) int {
    if n == 0 {
        return 0
    }
    if n == 1 {
        return 1
    }
    return fib(n-1) + fib(n-2)
}
```
这个算法的时间复杂度为: `O(2^n)`; n=40的时候运行时间就超过1秒了,而且fib增长速度很快,n比较大的时候就不能返回int了,只能返回int64

画出树状的调用结构,可以发现上面代码有大量的重复计算,例如`fib(5)`,会有`fib(3)`计算两次,`fib(2)`计算三次.可以增加一个缓存`memo`来解决重复计算的问题,这种解决方式叫**记忆化搜索**,代码修改之后变成了`O(n)`
```go
func fib(n int, memo *[]int) int {
    if n == 0 {
        return 0
    }
    if n == 1 {
        return 1
    }

    if (*memo)[n] == -1 {
        (*memo)[n] = fib(n-1) + fib(n-2)
    }

    return (*memo)[n]
}
```

记忆化搜索是自上而下地解决问题; 而动态规划是自下向上的解决问题: 先解决小数据量的问题,再层层递推,解决大数据量下的问题.如下代码,时间复杂度仍然是`O(n)`,但是没有递归调用,而且每个memo只会访问一次:
```go
func fib(int n) {
    memo := make([]int, n+1)

    memo[0] = 0
    memo[1] = 1
    for i := 2;i<=n;i++{
        memo[i] = memo[i-1] + memo[i-1]
    }
    return memo[n]
}
```

动态规划: 将原问题拆解成若干子问题,同时保存子问题的答案,使得每个子问题只求解一次,最终获得原问题的答案.

> dynamic programming (also known as dynamic optimization) is a method for solving a complex problem by breaking it down into a collection of simpler subproblems, solving each of those subproblems just once, and storing their solutions - ideally, using a memory-based data structure.

递归问题 => 重叠子问题 => 记忆化搜索/动态规划

### 9.3 发现重叠子问题
最优子结构:通过求子问题的最优解,可以获得原问题的最优解

### 9.4 状态的定义与状态转移
考虑偷取`[0...n-1]`范围内的所有房子
偷取0： 问题变成偷取`[2...n-1]`范围内的房子

状态的定义: 考虑偷取`[x...n-1]`范围内的房子

根据对状态的定义，决定状态的转移：
f(0) = max{v(0) + f(2), v(1) + f(3), v(2) + f(4), ...,v(n-3) + f(n-1), v(n-2), v(n-1)} (状态转移方程)

### 9.5 0-1背包问题
有一个背包,容量为C.现有n种不同的物品编号为0...n-1,其中每一件物品的重量为w(i),价值为v(i).问可以向这个背包中盛放哪些物品,使得在不超过背包容量的基础上,物品的总价值最大.

暴力解法: 每一件物品都可以放进背包,也可以不放进背包.
O((2^n)*n)

F(n, C)考虑将n个物品放入容量为C的背包,使得价值最大
```
// 情况一,不需要考虑第i件物品,则问题转换为这个式子
// 情况二, 需要考虑第i件物品,则问题转换为此
F(i, c) = max( F(i-1, c),  v(i) + F(i-1, c-w(i))  )
```

```go
// w为每件物品的总重量；v为价值；背包容量为C
// 需要返回物品的最大总价值
func knapsack(w []int, v []int, C int) int {
	wLen := len(w)
	k := Knapsack01{
		memo: make([][]int, wLen),
	}
	for i := 0; i < wLen; i++ {
		k.memo[i] = make([]int, C+1)
		for j := 0; j <= C; j++ {
			k.memo[i][j] = -1
		}
	}
	defer fmt.Println(k.memo)
	return k.bestValue(w, v, wLen-1, C)
}

type Knapsack01 struct {
	memo [][]int // 因为有两个约束条件:物品、剩余容积; 所以memo是一个二维数组,第一个key代表物品,第二个key代表剩余容量. 即memo[i][j] 代表第i个物品放入容量为j的背包时可以得到的最大的价值
}

// 用[0...index]的物品，填充容积为c的背包的最大价值
func (k *Knapsack01) bestValue(w []int, v []int, index int, c int) int {
	// 如果当前已经没有了物品/没有了容量
	if index < 0 || c <= 0 {
		return 0
	}

	if k.memo[index][c] != -1 {
		return k.memo[index][c]
	}

	// 情况1, 无视该物品
	res := k.bestValue(w, v, index-1, c)
	if c >= w[index] { // 如果该物品可以装进背包
		// 情况2，包含该物品
		res2 := k.bestValue(w, v, index-1, c-w[index]) + v[index]
		res = Helper.MaxInt(res, res2)
	}

	k.memo[index][c] = res
	return res
}

func main() {
	w := []int{
		0: 1,
		1: 2,
		2: 3,
	}
	v := []int{
		0: 6,
		1: 10,
		2: 12,
	}

	res := knapsack(w, v, 5)
	fmt.Println(res)
}
```

### 9.6 0-1背包问题的优化与变种
对于状态转移方程`F(i, c) = max(F(i-1, c), v(i) + F(i-1, c-w(i)))`第i行元素依赖于i-1行元素.理论上,只需要保持两行元素,空间复杂度变成O(2C) = O(C)

变种: 1. 完全背包问题: 每个物品可以无限使用;2.多重背包问题:么个物品不止一个,有num(i)个;3.多维费用背包问题,要考虑物品的体积与重量;4. 物品之间有排斥/依赖

### 9.7 面试中的背包问题

### 9.8 LIS 问题 Longest Increasing Subsequence
最长上升子序列


### 9.9 LCS、最短路等等
最长公共子序列Longest Common Subsequence




## 10 贪心算法

贪心算法与动态规划的关系

贪心选择性质: 在求解一个最优化的问题中,我们使用贪心的方式选择了一组内容之后,不会影响剩下的子问题的求解;

如果探讨一个问题无法使用贪心算法,举反例即可; 如果无法举出反例,如何证明贪心算法的正确性?  => 反证法

> 在算法中用到最多的数学证明方法:1. 数学归纳法;2. 反证法.

例如:(leetcode 435) 给定一组区间,问最多保留多少个区间,可以让这些区间互相不重叠? 贪心算法:按照区间的结尾排序,每次选择结尾最早的,而且和前一个区间不重叠的区间;

某次选择的是`[s(i), f(i)]`;其中f(i)是当前所有选择中结尾最早的

证明: 假设这个选择不是最优的.也就是说,如果这个问题的最优解为k,则这个选择得到的解,最少为k-1. 假设最优解在这一步选择`[s(j), f(j)]`中, f(j)>f(i)(因为f(i)是结尾最早的). 此时,显然可以将`[s(i), f(i)]`替换`[s(j), f(j)]`,而不影响后续区间选择.此时,当我们选择了`[s(i), f(i)]`时,也构成了一个大小为k的解. 但是和之前的假设矛盾. 

贪心算法为A;最优算法为O;发现A完全能替代O,且不影响求出最优解.


## 题目解法思路总结:
1. 数组: 双指针; 对撞指针; 滑动窗口
2. 字符串: 转换为字符串数组/byte数组;
3. 多个数组: 查找表(需要数据顺序性就使用平衡二叉树,不需要就使用哈希表)
4. 链表: 设置虚拟头节点(存在对头节点操作时), 双指针(leetcode19,删除倒数第x个元素);


