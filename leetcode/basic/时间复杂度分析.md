# 时间复杂度分析

## 什么是大O

1. n表示数据规模，O(f(n))表示运行算法所需要执行的指令数，和f(n)成正比; 

   - 如二分查找法O(logn),所需指令数:`a*logn`; 寻找数组中的最大/最小值O(n),所需指令数:`b*n`; 归并排序所需指令数：`c*nlogn`; 选择排序所需指令数：`dn^2`;

   - 因为算法讨论的都是超大数据量下的问题，时间复杂度大O讨论的是一个量级的问题，当n突破某个点的时候「时间复杂度低的算法」需要的时间一定比「时间复杂度高」的算法少。
   - 但是同理如果数据量小的情况下，复杂度高的算法在前面的常数级参数里可能会有小的优势。例如在进行归并排序与快排时，数据量很小时可以考虑用插入排序来进行优化。

2. 在学术界，严格地将，O(f(n))表示算法执行的上界；

   - 归并排序算法的时间复杂度是O(nlogn)的，同时也是O(n^2)
   - 在业界，我们使用O来表示算法执行的最低上界, 我们一般不会说归并排序是O(n^2)，而是O(nlogn)

3. 如果设计了一个算法有两个部分，那么整个算法应该以量级高的算法作为主导。

   - 如某个算法时间复杂度是`O(nlogn + n)`的，那么这个算法的时间复杂度应该是`O(nlogn)`。

   - 但是如果`O(AlogA + B)`,两部分的维度并不是相同的n，那么就不能省略掉B部分

     ```
     // 例如对邻接表实现图的遍历，时间复杂度是O(V + E)
     
     // 问题：有一个字符串数组，将数组中的每一个字符串按照字母序排序；之后再将整个字符串数组按照字典序排序。整个操作的时间复杂度是多少？
     
     // 解：1.假设最长字符串的长度为s；数组中有n个字符串
        对每个字符串排序O(slogs)
        2. 将数组中每个字符串按照字母序排序O(n*slog(s))
        3. 将整个字符串数组按照字典序排序O(s*nlog(n))，原因：对于计算机来说，「整数的比较」时间复杂度是O(1)级别的，所以整数排序是O(nlogn)级别的；但是「字符串的比较」时间复杂度是O(s)级别的，所以字符串排序的时间复杂度是O(s*nlog(n))级别的。
        4. 所以该题解是O(n*slog(s))+O(s*nlog(n))=O(n*s*logs+s*n*logn)=O(n*s*(logn+logs))
     ```

4. 算法复杂度在有些情况是用例相关的：
   - 比如插入排序算法O(n^2)，最差情况O(n^2)，最好情况是O(n)，即是在原数组本身有序的情况下。但是这个算法的平均情况是O(n^2)的。
   - 比如快速排序算法O(nlogn)，最差情况O(n^2)，即每次partition选取的值刚好是这个区间的最值;最好情况是O(nlogn)。但是这个算法的平均情况是O(nlogn)的。

## 对数据规模有个大概的概念

如果想要在1s之内解决问题：

1. O(n^2)的算法可以处理大约10^4级别的数据: 10000；
2. O(n)的算法可以处理大约10^8级别的数据: 1000万；
3. O(nlogn)的算法可以处理大约10^7级别的数据: 100万；

不同的计算机速度也不同，而且不同算法单次实际运行的时间也不同。通常建议将数据级别再除以10。

## 空间复杂度

1. 多开一个辅助数组O(n)；
2. 多开一个辅助的二维数组O(n^2)；
3. 多开常数空间O(1)；

> ps. 递归调用是有空间代价的，因为语言通常需要将前一级函数的状态压入栈中。例如正常计算空间复杂度为O(1)，那么递归调用空间复杂度是O(n)

## 常见的复杂度分析

1. 顺序执行，没有循环的操作，复杂度为O(1)
2. 存在一个for循环，通常复杂度为O(n)。值得注意的是，这个n前面通常带一个常数a，这个a可能大于1也有可能小于1。如下
```go
for i:= 0; i < n/2; i++ {
    // 
}
```
这个算法的复杂度是O(1/2*n)，仍然是O(n)级别的复杂度。

3. 存在一个嵌套的for循环,并且两次循环的次数都与n有关系，通常复杂度为O(n^2)。
```go
// O(n^2)的数学推导
for i:=0;i<n;i++ {
    minIndex := i
    for j:=i+1;j<n;j++ {
        // todo
    }
}
// 对于上面这段代码，执行todo操作次数为:
// (n-1) + (n-2) + (n-3) + ...+ 0
// = (0+n-1)*n/2    等差数列求和
// = (1/2)n*(n-1)
// = 1/2*n^2 - 1/2*n
// = O(n^2)
```

4. 复杂度O(logn)

   例1:二分查找法的复杂度是O(logn)的，因为它的流程是：
    1. 在n个元素中查找；
    2. 在n/2个元素中查找；
    3. 在n/4个元素中查找；
    4. ... 直到在1个元素中查找。

    n经过以2为底logn次「除以2」操作后等于1,即log2(n) = O(logn)  // 这里log2(n)表示为log2为底的n
   
   例2:
   ```php
   while(num) {
       //  todo
       num/=10
   }
   ```
   n经过几次「除以10」操作后等于0？即log10(n) = O(logn)
   而loga(n) 与logb(n)之间的关系是: loga(n) = loga(b) * logb(n), 即loga(n)与logb(n)之前的关系是loga(b)级的，是常数级的关系，是相对可以忽略不计的。


5. 复杂度O(nlogn)
   ```go
   for sz := 1; sz < n; sz +=sz {
       for i := 1; i  < n; i++  {
           fmt.Println("hello")
       }
   }
   ```
   对于上面这段代码，里面的循环走了n次，而外面的循环每次都是sz*2直到大于等于n，即n/2与sz的关系，是logn级别的。所以整个代码复杂度为O(nlogn)


6. 了解：复杂度O(sqrt(n)) 根号n级别的算法
   ```go
   for i := 2 ; i*i <= n; i++ {
   
   }
   ```



## 复杂度检查
自以为写了O(nlogn)算法，实际是O(n^2)的算法。如何检测。

方法：每次将数据规模提高两倍，看时间的变化。



## 递归算法的复杂度分析
**不是有递归的函数就一定是O(nlogn)!**

1. 递归中只进行一次递归调用，只要计算出递归调用的深度。
   > 如果在递归调用中，只进行一次递归调用，递归深度为depth，在每个递归函数中，时间复杂度为T；则总体的时间复杂度为O(T*depth)

   例如二分查找法的递归写法，递归调用的深度每次是n/2级别的，所以其时间复杂度是O(logn)级别的。
   ```go
   func binarySearch(arr []int, l int, r int, target int) int {
       if l > r {
           return -1
       }
   
       mid := (r - l) / 2  + l
       if arr[mid] == target {
           return mid
       } else if arr[mid] > target {
           return binarySearch(arr, l, mid - 1, target)
       } else {
           return binarySearch(arr, mid + 1, r, target)
       }
   }
   ```
   
   例2:计算x的n次方：x^n = x^(n/2) * x^(n/2)
   ```go
   func pow(x float64, n int) (float64, error) {
       if n < 0 {
           return 0, error.New("非法")
       }
       if n  == 0 {
           return 1.0
       }
   
       t := pow(x, n/2)
   
       if n%2 {
           return x*t*t
       }
       return t*t
   }
   ```
   注意一般求x^n，通常是连续n个x相乘，即复杂度为O(n)。这个算法的递归深度是logn，时间复杂度是O(logn)，要比传统的n个x相乘性能要好很多。
   
2. 递归中进行多次的递归调用，重点在计算调用的次数。可以将整个递归过程画成一棵树，则问题变化成求这棵树的节点次数。

   如一棵二叉树：2^0+2^1+2^2+2^3+...+2^n = 2^(n+1)-1 = O(2^n)。这是一个指数级算法，性能是极其慢的。
   
   但是在如归并排序的多次递归写法中：整棵树的深度是logn，并且每个节点的数据处理规模都是逐渐缩小的。所以复杂度是O(nlogn)级别的。
   ```go
   func mergeSort(arr []int, l int, r int) {
       if l >= r {
           return
       }
       mid := (r - l) / 2 + l
       mergeSort(arr, l, mid)
       mergeSort(arr, mid+1,r)
       merge(arr, l, mid,  r)
   }
   ```

3. 扩展 **主定理**：递归函数的时间复杂度的所有情况。

## 均摊时间复杂度分析
例：动态数组Vector添加元素的时间复杂度分析：在添加元素时如果数组长度已经等于容量capacity了，则执行resize操作，将数组容量翻倍。这个数组容量翻倍操作需要遍历整个数组，将其移动到新开辟的容量翻倍的数组中，这个复杂度为O(n)。而如果正常添加元素的操作，因为是直接添加到数组尾部，故复杂度为O(1)。

所以计算均摊复杂度时，添加n个元素时间复杂度为O(n)，resize操作为O(n)，则整体复杂度为O(2n)，故添加单个元素的复杂度为O(2)，就是O(1)。

> ps 关于动态数组的resize操作为什么数组大小n每次都要翻倍的原因：因为如果每次容量增加一个常数，假如这个常数是10000，那么在数据量在千万级别的时候这10000个新空间太小了，会导致过多的resize操作。而如果数据量在10级别的时候，这个新空间又太大了，极大浪费了空间。所以这个新空间大小最好是与数组大小n有关，所以一般选择与数组大小有关的最小的值，即2n。



## 避免复杂度的震荡
同样是动态数组vector，如果在弹出元素时，当前元素个数是容量的二分之一，那么进行resize操作，删除掉空的一半空间。这里就会出现复杂度震荡的问题。

如果数组容量在n，数组元素个数也在n，此时添加元素加resize的复杂度为O(n)；然后又删除一个元素，此时删除元素加resize的复杂度为O(n)；我们在这个临界点反复横跳，就会导致整体的添加元素与删除元素的复杂度由O(1)变成O(n)。这就是复杂度震荡的问题。

最好的解决思路是，在当前元素个数是容量的四分之一的时候再进行resize减少一半空间，这样保证了再添加操作时仍然有元素个数两倍的空间。



